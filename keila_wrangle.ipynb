{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d507db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keila_wrangle as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fc54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "white = pd.read_csv('winequality-white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf10190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 outliers removed from fixed acidity.\n",
      "26 outliers removed from volatile acidity.\n",
      "11 outliers removed from citric acid.\n",
      "5 outliers removed from residual sugar.\n",
      "63 outliers removed from chlorides.\n",
      "15 outliers removed from free sulfur dioxide.\n",
      "2 outliers removed from total sulfur dioxide.\n",
      "0 outliers removed from density.\n",
      "4 outliers removed from pH.\n",
      "21 outliers removed from sulphates.\n",
      "0 outliers removed from alcohol.\n",
      "0 outliers removed from quality.\n",
      "0 outliers removed from red_wine.\n",
      "\n",
      "Total of 193 outliers removed.\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = w.clean_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21df2d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (3782, 14)\n",
      "validate -> (1261, 14)\n",
      "test -> (1261, 14)\n"
     ]
    }
   ],
   "source": [
    "target = \"quality\"\n",
    "train, validate, test, x_train, y_train, x_validate, y_validate, x_test, y_test = w.split_data_xy(train, validate, test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a485a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled, x_validate_scaled, x_test_scaled = w.mm_scale(x_train, x_validate, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b982f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>ph</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.557034</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.074713</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.340067</td>\n",
       "      <td>0.283904</td>\n",
       "      <td>0.522124</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.538721</td>\n",
       "      <td>0.436629</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.551331</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.239057</td>\n",
       "      <td>0.565906</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.558685</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.683777</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.417508</td>\n",
       "      <td>0.449303</td>\n",
       "      <td>0.442478</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.195817</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.378327</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.208754</td>\n",
       "      <td>0.554499</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3782 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0          0.662791          0.144444     0.546512        0.028169   0.155172   \n",
       "1          0.337209          0.244444     0.337209        0.098592   0.074713   \n",
       "2          0.139535          0.255556     0.000000        0.267606   0.195402   \n",
       "3          0.372093          0.055556     0.430233        0.570423   0.172414   \n",
       "4          0.558140          0.155556     0.418605        0.056338   0.298851   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "3777       0.290698          0.655556     0.558140        0.558685   0.229885   \n",
       "3778       0.569767          0.077778     0.348837        0.042254   0.195402   \n",
       "3779       0.232558          0.200000     0.348837        0.089202   0.126437   \n",
       "3780       0.255814          0.266667     0.534884        0.037559   0.218391   \n",
       "3781       0.395349          0.288889     0.244186        0.084507   0.362069   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide   density        ph  \\\n",
       "0                    0.20              0.393939  0.557034  0.159292   \n",
       "1                    0.36              0.340067  0.283904  0.522124   \n",
       "2                    0.42              0.538721  0.436629  0.513274   \n",
       "3                    0.35              0.333333  0.551331  0.292035   \n",
       "4                    0.52              0.239057  0.565906  0.663717   \n",
       "...                   ...                   ...       ...       ...   \n",
       "3777                 0.56              0.727273  0.683777  0.398230   \n",
       "3778                 0.28              0.417508  0.449303  0.442478   \n",
       "3779                 0.74              0.414141  0.195817  0.424779   \n",
       "3780                 0.55              0.616162  0.378327  0.460177   \n",
       "3781                 0.40              0.208754  0.554499  0.575221   \n",
       "\n",
       "      sulphates   alcohol  red_wine  \n",
       "0      0.488372  0.250000       0.0  \n",
       "1      0.476744  0.550000       0.0  \n",
       "2      0.476744  0.316667       0.0  \n",
       "3      0.383721  0.450000       0.0  \n",
       "4      0.755814  0.500000       1.0  \n",
       "...         ...       ...       ...  \n",
       "3777   0.348837  0.216667       0.0  \n",
       "3778   0.186047  0.300000       0.0  \n",
       "3779   0.186047  0.583333       0.0  \n",
       "3780   0.313953  0.266667       0.0  \n",
       "3781   0.372093  0.350000       1.0  \n",
       "\n",
       "[3782 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dbc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vali, t = w.clean_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f084574",
   "metadata": {},
   "outputs": [],
   "source": [
    "1599 + 4898\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "6497 - 193\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d905cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wine():\n",
    "    red = pd.read_csv('winequality-red.csv')\n",
    "    white = pd.read_csv('winequality-white.csv')\n",
    "    return red, white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2125de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets \n",
    "red, white = read_wine()\n",
    "\n",
    "# create columns to seperate wine types --  encode\n",
    "red['red_wine'] = 1\n",
    "white['red_wine'] = 0\n",
    "\n",
    "red['wine_type'] = 'red'\n",
    "white['wine_type'] = 'white'\n",
    "# combine red & white wine dataset\n",
    "df = pd.concat([red, white])\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6171fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc621ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, exclude_column=[], sd=4):\n",
    "    \"\"\"\n",
    "    Remove outliers from a pandas DataFrame using the Z-score method.\n",
    "    \n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    num_outliers_total = 0\n",
    "    for column in df.columns:\n",
    "        if column == exclude_column:\n",
    "            continue\n",
    "        series = df[column]\n",
    "        z_scores = np.abs(stats.zscore(series))\n",
    "        num_outliers = len(z_scores[z_scores > sd])\n",
    "        num_outliers_total += num_outliers\n",
    "        df = df[(z_scores <= sd) | pd.isnull(df[column])]\n",
    "        print(f\"{num_outliers} outliers removed from {column}.\")\n",
    "    print(f\"\\nTotal of {num_outliers_total} outliers removed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wine():\n",
    "    # get datasets \n",
    "    red, white = read_wine()\n",
    "    \n",
    "    # create columns to seperate wine types --  encode\n",
    "    red['red_wine'] = 1\n",
    "    white['red_wine'] = 0\n",
    "\n",
    "    red['wine_type'] = 'red'\n",
    "    white['wine_type'] = 'white'\n",
    "    # combine red & white wine dataset\n",
    "    df = pd.concat([red, white])\n",
    "    \n",
    "    # reset index\n",
    "\n",
    "\n",
    "    \n",
    "    # remove outliers -- removed outliers outside of 4 standard deviation\n",
    "    df = remove_outliers(df, 'wine_type')\n",
    "#     df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "#     df = df.drop(columns=[\"index\"])\n",
    "    \n",
    "    # fix names for columns\n",
    "    new_col_name = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_col_name.append(col.lower().replace(' ', '_'))\n",
    "\n",
    "    df.columns = new_col_name\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18800562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e04994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61ee95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows & columns\n",
    "red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283aa442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows & columns\n",
    "white.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27904bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([red, white])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1483e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found no nulls \n",
    "df[df.isnull()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(df, feature, m=1.5):\n",
    "    '''\n",
    "    outlier will take in a dataframe's feature:\n",
    "    - calculate it's 1st & 3rd quartiles,\n",
    "    - use their difference to calculate the IQR\n",
    "    - then apply to calculate upper and lower bounds\n",
    "    - using the `m` multiplier\n",
    "    '''\n",
    "    q1 = df[feature].quantile(.25)\n",
    "    q3 = df[feature].quantile(.75)\n",
    "    \n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    upper_bound = q3 + (m * iqr)\n",
    "    lower_bound = q1 - (m * iqr)\n",
    "    \n",
    "    return upper_bound, lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b60a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[:-1]:\n",
    "    upper_bound, lower_bound = outlier(df, col)\n",
    "    print(col)\n",
    "    print(upper_bound)\n",
    "    print(lower_bound)\n",
    "    \n",
    "# there arent any crazy outliers -- leave in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_cols(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and identifies the columns that are object types\n",
    "    and returns a list of those column names. \n",
    "    '''\n",
    "    # get a list of the column names that are objects (from the mask)\n",
    "    object_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    return object_cols\n",
    "\n",
    "\n",
    "\n",
    "def get_numeric_cols(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and identifies the columns that are object types\n",
    "    and returns a list of those column names. \n",
    "    '''\n",
    "    # get a list of the column names that are objects (from the mask)\n",
    "    num_cols = df.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    return num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7173ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    '''\n",
    "    summarize will take in a single argument (a pandas dataframe) \n",
    "    and output to console various statistics on said dataframe, including:\n",
    "    # .head()\n",
    "    # .info()\n",
    "    # .describe()\n",
    "    # .value_counts()\n",
    "    # observation of nulls in the dataframe\n",
    "    # distribution of numerical attributes\n",
    "    '''\n",
    "    print(f\"\"\"SUMMARY REPORT\n",
    "=====================================================\n",
    "          \n",
    "          \n",
    "Dataframe head: \n",
    "{df.head(3)}\n",
    "          \n",
    "=====================================================\n",
    "          \n",
    "          \n",
    "Dataframe info: \"\"\")\n",
    "    df.info()\n",
    "\n",
    "    print(f\"\"\"=====================================================\n",
    "          \n",
    "          \n",
    "Dataframe Description: \n",
    "{df.describe().T}\n",
    "          \n",
    "=====================================================\n",
    "\n",
    "    \n",
    "    \n",
    "DataFrame value counts: \n",
    " \"\"\")         \n",
    "    for col in (get_object_cols(df)): \n",
    "        print(f\"\"\"******** {col.upper()} - Value Counts:\n",
    "{df[col].value_counts()}\n",
    "    _______________________________________\"\"\")                   \n",
    "        \n",
    "    for col in df.columns:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        sns.histplot(df[col], ax=ax)\n",
    "        ax.set_title(f'Histogram of {col}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf251c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.summarize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ccaefa",
   "metadata": {},
   "source": [
    "* sulphates, density, total sulfur dioxide, free sulfur dioxide, chlorides, residual sugar, citric acid, volatile acidity   has outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd00a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# removed outliers outside 4 standard deviation\n",
    "def remove_outliers(df, exclude_column=[], sd=4):\n",
    "    \"\"\"\n",
    "    Remove outliers from a pandas DataFrame using the Z-score method.\n",
    "    \n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame containing the data.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    num_outliers_total = 0\n",
    "    for column in df.columns:\n",
    "        if column == exclude_column:\n",
    "            continue\n",
    "        series = df[column]\n",
    "        z_scores = np.abs(stats.zscore(series))\n",
    "        num_outliers = len(z_scores[z_scores > sd])\n",
    "        num_outliers_total += num_outliers\n",
    "        df = df[(z_scores <= sd) | pd.isnull(df[column])]\n",
    "        print(f\"{num_outliers} outliers removed from {column}.\")\n",
    "    print(f\"\\nTotal of {num_outliers_total} outliers removed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle outliers\n",
    "df = w.remove_outliers(df, 'wine_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4738ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df):\n",
    "    \"\"\"\n",
    "    Analyzes missing values in a dataframe and returns a summary dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input dataframe containing observations and attributes.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe with information about missing values for each attribute.\n",
    "            The index represents attribute names, the first column contains the number of rows\n",
    "            with missing values for that attribute, and the second column contains the percentage\n",
    "            of total rows that have missing values for that attribute.\n",
    "    \"\"\"\n",
    "    missing_counts = df.isnull().sum()\n",
    "    total_rows = len(df)\n",
    "    missing_percentages = (missing_counts / total_rows) * 100\n",
    "    \n",
    "    missing_data_df = pd.DataFrame({'Missing Count': missing_counts, 'Missing Percentage': missing_percentages})\n",
    "    missing_data_df.index.name = 'Attribute'\n",
    "    \n",
    "    return missing_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e88131",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31377213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_column = .5, prop_required_row = .75):\n",
    "    \"\"\"\n",
    "    Drops rows and columns from a dataframe based on the proportion of missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input dataframe.\n",
    "        prop_required_column (float, optional): The proportion of non-missing values required for each column.\n",
    "            Defaults to 0.5.\n",
    "        prop_required_row (float, optional): The proportion of non-missing values required for each row.\n",
    "            Defaults to 0.75.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The modified dataframe with dropped columns and rows.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    Example:\n",
    "        modified_df = handle_missing_values(df, prop_required_column=0.6, prop_required_row=0.8)\n",
    "    \"\"\"\n",
    "    threshold = int(round(prop_required_column*len(df.index),0))\n",
    "    df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(df.columns),0))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_missing_values(df, prop_required_column = .5, prop_required_row = .75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns add underscores\n",
    "new_col_name = []\n",
    "\n",
    "for col in df.columns:\n",
    "    new_col_name.append(col.lower().replace(' ', '_'))\n",
    "\n",
    "df.columns = new_col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f582f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nulls_by_row(df, index_id = 'id'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_missing = df.isnull().sum(axis=1)\n",
    "    pct_miss = (num_missing / df.shape[1]) * 100\n",
    "    \n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_missing, 'percent_cols_missing': pct_miss})\n",
    "\n",
    "    rows_missing = df.merge(rows_missing,\n",
    "                        left_index=True,\n",
    "                        right_index=True).reset_index()[[index_id, 'num_cols_missing', 'percent_cols_missing']]\n",
    "    return rows_missing.sort_values(by='num_cols_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_missing = nulls_by_row(df, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5325f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, stratify_name=None):\n",
    "    '''\n",
    "    Takes in two arguments the dataframe name and the (\"stratify_name\" - must be in string format) to stratify  and \n",
    "    return train, validate, test subset dataframes will output train, validate, and test in that order\n",
    "    '''\n",
    "    train, test = train_test_split(df, #first split\n",
    "                                   test_size=.2, \n",
    "                                   random_state=123, \n",
    "                                   stratify=df[stratify_name])\n",
    "    train, validate = train_test_split(train, #second split\n",
    "                                    test_size=.25, \n",
    "                                    random_state=123,\n",
    "                                    stratify=train[stratify_name])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = df.columns.tolist()\n",
    "print(column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df, stratify_name='quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e87c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wine():\n",
    "    # get datasets \n",
    "    red, white = read_wine()\n",
    "    \n",
    "    # create columns to seperate wine types --  encode\n",
    "    red['red_wine'] = 1\n",
    "    white['red_wine'] = 0\n",
    "\n",
    "    red['wine_type'] = 'red'\n",
    "    white['wine_type'] = 'white'\n",
    "    # combine red & white wine dataset\n",
    "    df = pd.concat([red, white])\n",
    "    \n",
    "    # remove outliers -- removed outliers outside of 4 standard deviation\n",
    "    df = remove_outliers(df, 'wine_type')\n",
    "    \n",
    "    # fix names for columns\n",
    "    new_col_name = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        new_col_name.append(col.lower().replace(' ', '_'))\n",
    "\n",
    "    df.columns = new_col_name\n",
    "\n",
    "    # split data \n",
    "    train, validate, test = split_data(df, \"quality\")\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = clean_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_xy(train, validate, test, target):\n",
    "    '''\n",
    "    This function take in a dataframe performs a train, validate, test split\n",
    "    Returns train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "    and prints out the shape of train, validate, test\n",
    "    '''\n",
    "    #Split into X and y\n",
    "    x_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "\n",
    "    x_validate = validate.drop(columns=[target])\n",
    "    y_validate = validate[target]\n",
    "\n",
    "    x_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "\n",
    "    # Have function print datasets shape\n",
    "    print(f'train -> {train.shape}')\n",
    "    print(f'validate -> {validate.shape}')\n",
    "    print(f'test -> {test.shape}')\n",
    "   \n",
    "    return train, validate, test, x_train, y_train, x_validate, y_validate, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"quality\"\n",
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = split_data_xy(train, validate, test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06891cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"quality\"\n",
    "train, validate, test, x_train, y_train, x_validate, y_validate, x_test, y_test = split_data_xy(train, validate, test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc55758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col(df, list_of_columns=[]): \n",
    "    '''\n",
    "    Take df with incorrect names and will return a renamed df using the 'list_of_columns' which will contain a list of appropriate names for the columns  \n",
    "    '''\n",
    "    df = df.rename(columns=dict(zip(df.columns, list_of_columns)))\n",
    "    return df\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def mm_scale(x_train, x_validate, x_test):\n",
    "    \"\"\"\n",
    "    Apply MinMax scaling to the input data.\n",
    "\n",
    "    Args:\n",
    "        x_train (pd.DataFrame): Training data features.\n",
    "        x_validate (pd.DataFrame): Validation data features.\n",
    "        x_test (pd.DataFrame): Test data features.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]: Scaled versions of the input data\n",
    "            (x_train_scaled, x_validate_scaled, x_test_scaled).\n",
    "    \"\"\"\n",
    "    # remove string column wine_type\n",
    "    keep_col = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'ph', 'sulphates', 'alcohol', 'red_wine']\n",
    "    x_train, x_validate, x_test = x_train[keep_col], x_validate[keep_col], x_test[keep_col]\n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "\n",
    "\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_validate_scaled = scaler.transform(x_validate)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    col_name = list(x_train.columns)\n",
    "\n",
    "    x_train_scaled, x_validate_scaled, x_test_scaled = pd.DataFrame(x_train_scaled), pd.DataFrame(x_validate_scaled), pd.DataFrame(x_test_scaled)\n",
    "    x_train_scaled, x_validate_scaled, x_test_scaled  = rename_col(x_train_scaled, col_name), rename_col(x_validate_scaled, col_name), rename_col(x_test_scaled, col_name)\n",
    "    \n",
    "    return x_train_scaled, x_validate_scaled, x_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ce9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled, x_validate_scaled, x_test_scaled = mm_scale(x_train, x_validate, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f49b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
